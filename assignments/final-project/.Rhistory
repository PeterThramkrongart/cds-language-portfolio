library(sf)
library(raster)
reticulate::repl_python()
"""
n
library(knitr)
library(rmdformats)
## Global options
options(max.print="75")
opts_chunk$set(echo=TRUE,
cache=TRUE,
prompt=FALSE,
tidy=TRUE,
comment=NA,
message=FALSE,
warning=FALSE)
opts_knit$set(width=75)
# Library
library(raster)
library(rgeos)
library(sf)
library(tidyverse)
library(htmltools)
library(googlesheets4)
library(mapview)
# Load the spatial data, project to UTM
# mun_sp<- getData('GADM', country = 'DK', level = 2)
mun_sp <- readRDS("data/gadm36_DNK_2_sp.rds")
mun_sf <- st_as_sf(mun_sp)
mun <- st_transform(mun_sf, crs = 32632)
mapview(mun)
# Straighten the names
sort(mun$NAME_2)
which(grepl("Å",mun$NAME_2))
which(grepl("Vest",mun$NAME_2))
mun$NAME_2[31] <- "Aarhus"
mun$NAME_2[21] <- "Høje-Taastrup"
mun$NAME_2[60] <- "Vesthimmerlands"
# Load the spatial data, project to UTM
# mun_sp<- getData('GADM', country = 'DK', level = 2)
mun_sp <- readRDS("data/gadm36_DNK_2_sp.rds")
mun_sf <- st_as_sf(mun_sp)
mun <- st_transform(mun_sf, crs = 32632)
mapview(mun)
# Straighten the names
sort(mun$NAME_2)
which(grepl("Å",mun$NAME_2))
which(grepl("Vest",mun$NAME_2))
mun$NAME_2[31] <- "Aarhus"
mun$NAME_2[21] <- "Høje-Taastrup"
mun$NAME_2[60] <- "Vesthimmerlands"
# Load the attributes
elec <- read_sheet("https://docs.google.com/spreadsheets/d/1ty3UrUiCK2iqWVk2T2GORaCl0QZ6feUTMmTakXPVIIg/edit#gid=0", col_types = "ccnnn")
0
library(knitr)
library(rmdformats)
## Global options
options(max.print="75")
opts_chunk$set(echo=TRUE,
cache=TRUE,
prompt=FALSE,
tidy=TRUE,
comment=NA,
message=FALSE,
warning=FALSE)
opts_knit$set(width=75)
# Library
library(raster)
library(rgeos)
library(sf)
library(tidyverse)
library(htmltools)
library(googlesheets4)
library(mapview)
# Load the spatial data, project to UTM
# mun_sp<- getData('GADM', country = 'DK', level = 2)
mun_sp <- readRDS("data/gadm36_DNK_2_sp.rds")
mun_sf <- st_as_sf(mun_sp)
mun <- st_transform(mun_sf, crs = 32632)
mapview(mun)
# Straighten the names
sort(mun$NAME_2)
which(grepl("Å",mun$NAME_2))
which(grepl("Vest",mun$NAME_2))
mun$NAME_2[31] <- "Aarhus"
mun$NAME_2[21] <- "Høje-Taastrup"
mun$NAME_2[60] <- "Vesthimmerlands"
# Let's map the two most popular parties, SD and Danske Folkeparti through time
library(tmap)
elections %>%
filter(grepl("^A|^O",Party)) %>%
tm_shape() +
tm_facets("Party", ncol = 2) +
tm_polygons("pct_vote2011",
title= "Percentage of Votes")
# Load the attributes
elec <- read_sheet("https://docs.google.com/spreadsheets/d/1ty3UrUiCK2iqWVk2T2GORaCl0QZ6feUTMmTakXPVIIg/edit#gid=0", col_types = "ccnnn")
# Load the attributes
elec <- read_sheet("https://docs.google.com/spreadsheets/d/1ty3UrUiCK2iqWVk2T2GORaCl0QZ6feUTMmTakXPVIIg/edit#gid=0", col_types = "ccnnn")
elec <- read_sheet("https://docs.google.com/spreadsheets/d/1ty3UrUiCK2iqWVk2T2GORaCl0QZ6feUTMmTakXPVIIg/edit#gid=0", col_types = "ccnnn")
# Load the attributes
# elec <- read_sheet("https://docs.google.com/spreadsheets/d/1ty3UrUiCK2iqWVk2T2GORaCl0QZ6feUTMmTakXPVIIg/edit#gid=0", col_types = "ccnnn")
# write_csv(elec, "data/elections.csv")
elec <- read_csv("data/elections.csv")
# Load the attributes
# elec <- read_sheet("https://docs.google.com/spreadsheets/d/1ty3UrUiCK2iqWVk2T2GORaCl0QZ6feUTMmTakXPVIIg/edit#gid=0", col_types = "ccnnn")
# write_csv(elec, "data/elections.csv")
elec <- read_csv("data/elections.csv")
# Check names
sort(unique(elec$Region))
# Check out the data
elec %>%
group_by(Party) %>%
summarize(sum2011 = sum(Y2011),
sum2015 = sum(Y2015),
sum2019 = sum(Y2019))  %>%
janitor::adorn_totals(where = "row")
# Load the attributes
# elec <- read_sheet("https://docs.google.com/spreadsheets/d/1ty3UrUiCK2iqWVk2T2GORaCl0QZ6feUTMmTakXPVIIg/edit#gid=0", col_types = "ccnnn")
# write_csv(elec, "data/elections.csv")
elec <- read_csv("data/elections.csv")
# Check names
sort(unique(elec$Region))
# Check out the data
elec %>%
group_by(Party) %>%
summarize(sum2011 = sum(Y2011),
sum2015 = sum(Y2015),
sum2019 = sum(Y2019))  %>%
janitor::adorn_totals(where = "row")
# Create total electorate per municipality
electorate <- elec %>%
group_by(Region) %>%
summarize(sum2011 = sum(Y2011),
sum2015 = sum(Y2015),
sum2019 = sum(Y2019))
# Merge the summary with the granual election dataset and spatial polygons
elections <- mun %>%
select(NAME_2) %>%
merge(elec, by.x = "NAME_2",by.y ="Region") %>%
merge(electorate, by.x = "NAME_2",by.y ="Region") %>%
group_by(NAME_2, Party) %>%
mutate(pct_vote2011 = Y2011/sum2011*100,
pct_vote2015 = Y2015/sum2015*100,
pct_vote2019 = Y2019/sum2019*100)
elections
# Map some aspect of the result to see no counties are missing
elections %>%
group_by(NAME_2) %>%
filter(grepl("^A", Party)) %>%  # A.Socialdemokratie
select(pct_vote2015) %>%
mapview()
# Save for later?
write_rds(elections, "data/elections_sp.rds")
# Let's map the two most popular parties, SD and Danske Folkeparti through time
library(tmap)
elections %>%
filter(grepl("^A|^O",Party)) %>%
tm_shape() +
tm_facets("Party", ncol = 2) +
tm_polygons("pct_vote2011",
title= "Percentage of Votes")
elections %>%
filter(grepl("^A|^O",Party)) %>%
tm_shape() +
tm_facets("Party") +
tm_polygons("pct_vote2015",
title= "Percentage of Votes")
elections %>%
filter(grepl("^A|^O",Party)) %>%
tm_shape() +
tm_facets("Party") +
tm_polygons("pct_vote2019",
title= "Percentage of Votes")
# Use the cartogram package
library(cartogram)
library(sf)
# Let's look at Danske Folkeparti in 2015
DKF <- elections %>%
filter(grepl("^O",Party))
# Make a scatterplot of municipality electorate versus area and Danske Folkeparti voters and municipality area
names(DKF)
plot(DKF$sum2015, st_area(DKF, byid = TRUE))
plot(DKF$pct_vote2015, st_area(DKF, byid = TRUE))
# Make a cartogram, scaling the area to the electorate
electorate2015 <- cartogram_cont(DKF, "sum2015")
# Now check the linearity of the electorate per municipality plot
plot(electorate2015$sum2015, st_area(electorate2015, byid = TRUE))
# Make a cartogram, scaling the area to the percentage of DF voters
DF2015 <- cartogram_cont(DKF, "pct_vote2015")
# Check the linearity of the DF voter percentage per municipality plot
plot(DF2015$pct_vote2015, st_area(DF2015, byid = TRUE))
# Make a fairer map of the DF voter percentage in 2015
plot(electorate2015$geometry,
col = "beige",
main = "Electorate in DK municipalities 2015")
plot(DF2015$geometry,
col="pink",
main = "% of Danske Folkeparti voters across DK in 2015")
# Let's look at Social Democrats in 2015
DKSD <- elections %>%
filter(grepl("^A",Party))
# Make a cartogram, scaling the area to the total number of votes cast in 2015
electorate2015 <- cartogram_cont(DKSD, "sum2015")
# Now check the linearity of the total voters per municipality plot
plot(electorate2015$sum2015, st_area(electorate2015, byid = TRUE))
# Make a cartogram, scaling the area to the percentage of SD voters
DF2015 <- cartogram_cont(DKSD, "pct_vote2015")
# Check the linearity of the SD voters percentage per municipality plot
plot(DF2015$pct_vote2015, st_area(DF2015, byid = TRUE))
# Make a adjusted map of the 2015 SD voters
plot(electorate2015$geometry,
col = "beige",
main = "Electorate in DK municipalities 2015")
plot(DF2015$geometry,
col="pink",
main = "% of Social Democrat votes across DK in 2015")
library(tidyverse)
library(gstat)
library(raster)
# Reload kaz_geo, missing value dataframe and the v_model
kaz_geo <- read_csv("data/Kaz_geo.csv")
getwd()
# Reload kaz_geo, missing value dataframe and the v_model
kaz_geo <- read_csv("data/KAZ_geo.csv")
kaz_geo <- st_as_sf(kaz_geo, coords = c("Long","Lat"),crs = 4326)
plot(kaz_geo_geometry)
plot(kaz_geo$geometry)
hist(kaz_geo$OM_muns)
summary(kaz_geo$OM_muns)
kaz_sites <- st_read("data/KAZ_scatterpoints.shp")
st_crs(kaz_sites)
ggplot(kaz_geo)+
geom_sf(aes(col = OM_muns))+
geom_sf(kaz_sites, aes(col = Notes))
plot(kaz_geo$geometry);plot(kaz_sites$geometry, col = "red", add = T)
plot(kaz_geo$geometry);plot(kaz_sites$geometry, col = "red", add = T)
ggplot(kaz_geo)+
geom_sf(aes(col = OM_muns))
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(sf)
# Are there coordinates and what are they called?
names(kaz_geo)
kaz_geo$X <- st_coordinates(kaz_geo)[,1]
kaz_geo$Y <- st_coordinates(kaz_geo)[,2]
# Complete the formula
m_trend <- lm(OM_muns ~ X + Y, kaz_geo)
# Check the coefficients
summary(m_trend)
# Load data
# See what OM_muns measurements are at each location
# Get a summary of the organic matter (OM) values
# Look at the distribution
# Plot a map of organic matter
# Plot both the sampled and unsampled locations
kaz_geo <- read_csv("data/KAZ_geo.csv")
kaz_geo <- st_as_sf(kaz_geo, coords = c("Long","Lat"),crs = 4326)
kaz_geo = st_transform(kaz_geo,crs = 32635 )
plot(kaz_geo$geometry)
hist(kaz_geo$OM_muns)
summary(kaz_geo$OM_muns)
kaz_sites <- st_read("data/KAZ_scatterpoints.shp")
st_crs(kaz_sites)
ggplot(kaz_geo)+
geom_sf(aes(col = OM_muns))
plot(kaz_geo$geometry);plot(kaz_sites$geometry, col = "red", add = T)
# Are there coordinates and what are they called?
names(kaz_geo)
kaz_geo$X <- st_coordinates(kaz_geo)[,1]
kaz_geo$Y <- st_coordinates(kaz_geo)[,2]
# Complete the formula
m_trend <- lm(OM_muns ~ X + Y, kaz_geo)
# Check the coefficients
summary(m_trend)
# Create a data frame of missing data
kaz_sites %>%
mutate(X = st_coordinates(.)[,1],
y = st_coordinates(.)[,2],
OM = "NA",
ID = as.nuemric(TRAP_Code)) %>%
select(ID,X,Y,OM)
# Create a data frame of missing data
kaz_sites %>%
mutate(X = st_coordinates(.)[,1],
y = st_coordinates(.)[,2],
OM = "NA",
ID = as.numeric(TRAP_Code)) %>%
select(ID,X,Y,OM)
# Create a data frame of missing data
kaz_sites %>%
mutate(X = st_coordinates(.)[,1],
Y = st_coordinates(.)[,2],
OM = "NA",
ID = as.numeric(TRAP_Code)) %>%
select(ID,X,Y,OM)
# Predict OM for the missing data
predictions <- predict(m_trend, newdata = kaz_geo_miss, se.fit = TRUE)
# Create a data frame of missing data
kaz_geo_miss<- kaz_sites %>%
mutate(X = st_coordinates(.)[,1],
Y = st_coordinates(.)[,2],
OM = "NA",
ID = as.numeric(TRAP_Code)) %>%
select(ID,X,Y,OM)
# Predict OM for the missing data
predictions <- predict(m_trend, newdata = kaz_geo_miss, se.fit = TRUE)
kaz_geo_miss$OM <- predictions$fit
# Compute the exceedance probability
pFertile <- 1 - pnorm(5, mean = predictions$fit, sd = predictions$se.fit)
hist(pFertile)
# Load gstat and sp library
library(gstat)
library(sp)
# Example with Markers
library(leaflet)
library(htmlwidgets)
popup = c("Robin", "Jakub", "Jannes")
leaflet() %>%
addProviderTiles("Esri.WorldPhysical") %>%
#addProviderTiles("Esri.WorldImagery") %>%
addAwesomeMarkers(lng = c(-3, 23, 11),
lat = c(52, 53, 49),
popup = popup)
## Sydney with setView
leaflet() %>%
addTiles() %>%
addProviderTiles("Esri.WorldImagery",
options = providerTileOptions(opacity=0.5)) %>%
setView(lng = 151.005006, lat = -33.9767231, zoom = 10)
# Europe with Layers
leaflet() %>%
addTiles() %>%
setView( lng = 2.34, lat = 48.85, zoom = 5 ) %>%
addProviderTiles("Esri.WorldPhysical", group = "Physical") %>%
addProviderTiles("Esri.WorldImagery", group = "Aerial") %>%
addProviderTiles("MtbMap", group = "Geo") %>%
addLayersControl(
baseGroups = c("Geo","Aerial", "Physical"),
options = layersControlOptions(collapsed = T))
# Set the location and zoom level
leaflet() %>%
setView(151.2339084, -33.85089, zoom = 13) %>%
addTiles()  # checking I am in the right area
l_aus <- leaflet() %>%   # assign the base location to an object
setView(150.314, -33.74, zoom = 13)
esri <- grep("^Esri", providers, value = TRUE)
for (provider in esri) {
l_aus <- l_aus %>% addProviderTiles(provider, group = provider)
}
AUSmap <- l_aus %>%
addLayersControl(baseGroups = names(esri),
options = layersControlOptions(collapsed = FALSE)) %>%
addMiniMap(tiles = esri[[1]], toggleDisplay = TRUE,
position = "bottomright") %>%
addMeasure(
position = "bottomleft",
primaryLengthUnit = "meters",
primaryAreaUnit = "sqmeters",
activeColor = "#3D535D",
completedColor = "#7D4479") %>%
htmlwidgets::onRender("
function(el, x) {
var myMap = this;
myMap.on('baselayerchange',
function (e) {
myMap.minimap.changeLayer(L.tileLayer.provider(e.name));
})
}")
addControl("", position = "topright")
providers
class(providers)
?data.frame
test = data.frame(long = NULL,lat = NULL)
View(test)
View(test)
test
long = NULL
lat = NULL
data.frame(long,lat)
shiny::runApp('~/testApp')
webshot::install_phantomjs()
runApp('~/testApp')
library(parallel)
parallel::detectCores()
**step 3: run the python script:**
- Navigate to the folder "src".
```console
cd src
```
- run the python script _network_analysis.py_ and specify the desired arguments:
clearBounds()
setwd("~cds-language-portfolio/assignments/assignment-4")
setwd("~/cds-language-portfolio/assignments/assignment-4")
import tidyverse
library(tidyverse)
read_csv("data/processed/measures_of_centrality.csv")
head(data)
data
data = read_csv("data/processed/measures_of_centrality.csv")
head(data)
pacman::p_load(kable)
pacman::p_load(Kable)
knitr::kable(head(data))
knitr::kable(head(data, 20))
knitr::kable(head(order(data, betweenness)))
?order
data %>% arrange(desc(betweenness)) %>% head(20) %>% knitr::kable()
data %>% arrange(betweenness) %>% head(20) %>% knitr::kable()
data %>% arrange(desc(betweenness)) %>% head(20) %>% knitr::kable()
data %>% arrange(desc(degree)) %>% head(20) %>% knitr::kable()
getwd()
setwd("/home/cds-au615814/cds-language-portfolio/assignments/final_project")
setwd("/home/cds-au615814/cds-language-portfolio/assignments/final-project")
read_csv("reports/recommendations/1984_recs.csv")
help("read_csv")
read.table("reports/recommendations/1984_recs.csv",row.names = 1)
0
read.table("reports/recommendations/1984_recs.csv",row.names = 0)
read.table("reports/recommendations/1984_recs.csv",row.names = 1)
read_csv("reports/recommendations/1984_recs.csv")
read_csv("reports/recommendations/1984_recs.csv") %>% select(-"X1")
read_csv("reports/recommendations/1984_recs.csv") %>% select(-"X1")
test <-  read_csv("reports/recommendations/1984_recs.csv") %>% select(-"X1")
View(test)
read_csv("reports/recommendations/1984_recs.csv") %>% select(-"X1") %>% kable()
read_csv("reports/recommendations/1984_recs.csv") %>% select(-"X1") %>% head(10) %>% kable()
read_csv("reports/recommendations/1984_recs.csv") %>% select(c("book_title","book_authors","genres","rec_score")) %>% head(10) %>% kable()
help(genre)
help(kable)
read_csv("reports/recommendations/1984_recs.csv") %>% select(c("book_title","book_authors","genres","rec_score")) %>% head(10) %>% kable("simple")
read_csv("reports/recommendations/1984_recs.csv") %>% select(c("book_title","book_authors","genres","rec_score")) %>% head(10) %>% kable("pipe")
read_csv("reports/recommendations/1984_recs.csv") %>% select(c("book_title","book_authors","genres","rec_score")) %>% head(10) %>% kable( "latex")
read_csv("reports/recommendations/1984_recs.csv") %>% select(c("book_title","book_authors","rec_score")) %>% head(10) %>% kable( "pipe")
read_csv("reports/recommendations/It_recs.csv") %>% select(c("book_title","book_authors","rec_score")) %>% head(10) %>% kable( "pipe")
read_csv("reports/recommendations/The Green Mile_recs.csv") %>% select(c("book_title","book_authors","rec_score")) %>% head(10) %>% kable( "pipe")
read_csv("reports/recommendations/The Hobbit_recs.csv") %>% select(c("book_title","book_authors","rec_score")) %>% head(10) %>% kable( "pipe")
read_csv("reports/recommendations/The Idiot_recs.csv") %>% select(c("book_title","book_authors","rec_score")) %>% head(10) %>% kable( "pipe")
read_csv("reports/recommendations/Ulysses_recs.csv") %>% select(c("book_title","book_authors","rec_score")) %>% head(10) %>% kable( "pipe")
read_csv("reports/recommendations/A Games of Thrones_recs.csv") %>% select(c("book_title","book_authors","rec_score")) %>% head(10) %>% kable( "pipe")
read_csv("reports/recommendations/A Games of Thrones_recs.csv") %>% select(c("book_title","book_authors","rec_score")) %>% kable( "pipe")
read_csv("reports/recommendations/A Game of Thrones_recs.csv") %>% select(c("book_title","book_authors","rec_score")) %>% head(10) %>% kable( "pipe")
read_csv("reports/recommendations/The Hunger Games.csv") %>% select(c("book_title","book_authors","rec_score")) %>% head(10) %>% kable( "pipe")
read_csv("reports/recommendations/The Hunger Games_rex.csv") %>% select(c("book_title","book_authors","rec_score")) %>% head(10) %>% kable( "pipe")
read_csv("reports/recommendations/The Hunger Games_recs.csv") %>% select(c("book_title","book_authors","rec_score")) %>% head(10) %>% kable( "pipe")
read_csv("reports/recommendations/The Dark Tower_recs.csv") %>% select(c("book_title","book_authors","rec_score")) %>% head(10) %>% kable( "pipe")
read_csv("reports/recommendations/Ulysses_recs.csv") %>% select(c("book_title","book_authors","rec_score")) %>% head(10) %>% kable( "pipe")
read_csv("reports/recommendations/Ulysses_recs.csv") %>% select(c("book_title","book_authors","rec_score")) %>% head(10) %>% kable( "pipe")
read_csv("reports/recommendations/Ulysses_recs.csv") %>%thors","rec_score")) %>% head(10) %>% kable( "pipe")
read_csv("reports/recommendations/Ulysses_recs.csv") %>% select(c("book_title","book_authors","rec_score")) %>% head(10) %>% kable( "pipe")
read_csv("reports/recommendations/The Hunger Games_recs.csv") %>% select(c("book_title","book_authors","rec_score")) %>% head(10) %>% kable( "pipe")
read_csv("reports/recommendations/The Idiot.csv") %>% select(c("book_title","book_authors","rec_score")) %>% head(10) %>% kable( "pipe")
read_csv("reports/recommendations/A Game of Thrones.csv") %>% select(c("book_title","book_authors","rec_score")) %>% head(10) %>% kable( "pipe")
read_csv("reports/recommendations/A Game of Thrones_recs.csv") %>% select(c("book_title","book_authors","rec_score")) %>% head(10) %>% kable( "pipe")
read_csv("reports/recommendations/A Feast for Crows_recs.csv") %>% select(c("book_title","book_authors","rec_score")) %>% head(10) %>% kable( "pipe")
read_csv("reports/recommendations/The Dark Tower_recs.csv") %>% select(c("book_title","book_authors","rec_score")) %>% head(10) %>% kable( "pipe")
read_csv("reports/recommendations/1984_recs.csv") %>% select(c("book_title","book_authors","rec_score")) %>% head(10) %>% kable( "pipe")
reticulate::repl_python()
